ENV=dev

# API Keys - Replace with your actual keys
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

DB_HOST=localhost
DB_USER=postgres
DB_PASS=change-this-password-in-production
DB_NAME=core_db
DB_PORT=5432

# Security - Generate strong random values for production
JWT_SECRET_KEY=replace-with-32-char-random-string-here
FERNET_KEY=replace-with-fernet-key-from-generate-key
USE_SSL=false

# Enable/disable WebSocket backend (connect, broadcast, rooms)
USE_WS=true
SSL_KEYFILE_PATH=./certs/key.pem
SSL_CERTFILE_PATH=./certs/cert.pem

DEBUG=true
FASTAPI_DEBUG=true
LOG_LEVEL=DEBUG
FASTAPI_RUN_PORT=8000
SQL_ALCHEMY_LOGGING_LEVEL=ERROR
RELOAD=true

# Enable/disable rate limiting
RATE_LIMIT_ENABLED=true
# "redis" or "memory"
RATE_LIMIT_STORAGE_BACKEND=redis
# Global rate limits
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
# Auth endpoint rate limits (stricter)
RATE_LIMIT_AUTH_PER_MINUTE=5
RATE_LIMIT_AUTH_PER_HOUR=20
# Conversation endpoint rate limits
RATE_LIMIT_CONVERSATION_START_PER_MINUTE=10
RATE_LIMIT_CONVERSATION_START_PER_HOUR=100
# 30 conversation updates per minute per conversation (agent)
RATE_LIMIT_CONVERSATION_UPDATE_PER_MINUTE=30
# 500 conversation updates per hour per conversation (agent)
RATE_LIMIT_CONVERSATION_UPDATE_PER_HOUR=500

# AWS Credentials - Replace with your actual credentials
AWS_ACCOUNT_ID=xxxxxxxxxxxx
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIAxxxxxxxxxxxxxxxx
AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AWS_RECORDINGS_BUCKET=your-recordings-bucket-name
#AWS_S3_TEST_BUCKET=your-test-bucket-name

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_SSL=false # set to true if using Redis SSL
#REDIS_USER=redis
#REDIS_PASSWORD=  # Optional; set for Redis AUTH (e.g. managed/cloud Redis)
#REDIS_OVERRIDE_URL= redis://localhost:6379  # Optional; set for Redis Cluster mode

# Redis connection pool settings
REDIS_FOR_CONVERSATION=true
REDIS_MAX_CONNECTIONS=10
REDIS_MAX_CONNECTIONS_FOR_ENDPOINT_CACHE=5
REDIS_SOCKET_TIMEOUT=10
REDIS_SOCKET_CONNECT_TIMEOUT=15 # seconds

PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

# Opik Configuration
USE_OPIK=FALSE
OPIK_URL_OVERRIDE=https://www.comet.com/opik/api
OPIK_WORKSPACE=your-workspace-name
OPIK_API_KEY=your-comet-api-key
OPIK_PROJECT_NAME=your-project-name

# Zendesk Configuration
ZENDESK_SUBDOMAIN=your-subdomain
ZENDESK_EMAIL=your-email@example.com
ZENDESK_API_TOKEN=your-zendesk-api-token
ZENDESK_CUSTOM_FIELD_CONVERSATION_ID=0

WHISPER_TRANSCRIBE_SERVICE=http://localhost:8001/transcribe

# Google/Microsoft API Keys
GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
MICROSOFT_CLIENT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
MICROSOFT_CLIENT_SECRET=xxxxxxxxxxxxxxxxxxxxxxxx
MICROSOFT_TENANT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

# Vector Database Configuration
CHROMA_HOST=localhost # if in development with backend running inside IDE(non docker) otherwise remove this variable
CHROMA_PORT=8005 # if in development with backend running inside IDE(non docker) otherwise remove this variable
QDRANT_HOST=http://localhost
QDRANT_PORT=6333

# Multi-tenant Configuration
MULTI_TENANT_ENABLED=true
TENANT_HEADER_NAME=x-tenant-id
TENANT_SUBDOMAIN_ENABLED=False

CORS_ALLOWED_ORIGINS=*

# reCAPTCHA Configuration
RECAPTCHA_ENABLED=False
RECAPTCHA_PROJECT_ID=your-project-id
RECAPTCHA_SITE_KEY=your-site-key
RECAPTCHA_MIN_SCORE=0.5 # 0.0 - 1.0
GCP_SVC_ACCOUNT=your-base64-encoded-credentials

# Azure Blob Storage
AZURE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=your-account;AccountKey=your-key;EndpointSuffix=core.windows.net
AZURE_ACCOUNT_NAME=your-account-name
AZURE_ACCOUNT_KEY=your-account-key
AZURE_CONTAINER_NAME=your-container-name

MSSQL_DRIVER=ODBC+Driver+18+for+SQL+Server

# Bedrock embedding
BEDROCK_MAX_RETRY_QUERY_EMBEDDING=3
BEDROCK_TIMEOUT_QUERY_EMBEDDING_SECONDS=8

# S3 Storage Bucket Name -> Files
AWS_BUCKET_NAME=your-s3-bucket-name
# File Manager
FILE_MANAGER_ENABLED=false
# File Manager Provider -> local, s3, azure, gcs, sharepoint
FILE_MANAGER_PROVIDER=local

# Celery cleanup stale conversations cron (Run at 2 minutes past every 30 minutes)
CELERY_CLEANUP_STALE_CONVERSATIONS_CRON=2-59/30